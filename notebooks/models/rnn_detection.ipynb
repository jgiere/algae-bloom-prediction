{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input, Flatten, ConvLSTM2D, Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variables to be used in Keras and the CNN\n",
    "\n",
    "# number of items to use for training\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# Number of identifying classes \n",
    "#   WE have two, Bloom and no bloom 1/0\n",
    "NUM_CLASSES = 2 \n",
    "\n",
    "# number of times to repeat process\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "df_train = pd.read_csv('../../data/cleaned/site1_vineyard.csv')\n",
    "df_test = pd.read_csv('../../data/cleaned/site2_bird.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.37</td>\n",
       "      <td>2184</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.70</td>\n",
       "      <td>92.2</td>\n",
       "      <td>9.16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.428449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>15.45</td>\n",
       "      <td>2139</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>9.92</td>\n",
       "      <td>93.3</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.428449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>15.49</td>\n",
       "      <td>2057</td>\n",
       "      <td>-102.3</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.90</td>\n",
       "      <td>94.8</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.856898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>15.67</td>\n",
       "      <td>1978</td>\n",
       "      <td>-102.6</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.62</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.856898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>15.34</td>\n",
       "      <td>2136</td>\n",
       "      <td>-100.2</td>\n",
       "      <td>8.41</td>\n",
       "      <td>9.88</td>\n",
       "      <td>92.7</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.428449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.37             2184   -100.0  8.41   \n",
       "1          5/5/2017      0:15   15.45             2139   -101.0  8.43   \n",
       "2          5/5/2017      0:30   15.49             2057   -102.3  8.45   \n",
       "3          5/5/2017      0:45   15.67             1978   -102.6  8.45   \n",
       "4          5/5/2017      1:00   15.34             2136   -100.2  8.41   \n",
       "\n",
       "   Turbidity (NTU)  ODOSat%  ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)  \n",
       "0            10.70     92.2        9.16                  0.1    0.428449  \n",
       "1             9.92     93.3        9.25                  0.1    0.428449  \n",
       "2             8.90     94.8        9.40                  0.2    0.856898  \n",
       "3             8.62     96.0        9.49                  0.2    0.856898  \n",
       "4             9.88     92.7        9.22                  0.1    0.428449  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df_train['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "df_train = df_train.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "df_train['BGA (ug/L)'] = target\n",
    "df_train.head(5)\n",
    "\n",
    "\n",
    "target = df_test['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "df_test = df_test.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "df_test['BGA (ug/L)'] = target\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = df_train['Date (mm.dd.yyyy)'] + ' '+ df_train['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "df_train['Timestamp'] = timestamp\n",
    "\n",
    "timestamp = df_test['Date (mm.dd.yyyy)'] + ' '+ df_test['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "df_test['Timestamp'] = timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont need data and time now that we have Timestamp. Lets remove them\n",
    "\n",
    "df_train = df_train.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n",
    "df_test = df_test.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = df_train['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "df_train['Bloom'] = train_target\n",
    "\n",
    "test_target = df_test['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "df_test['Bloom'] = test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# lets try to normalize this now....\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset_columns = ['Temp C','Sp Cond (uS/cm)', 'pH (mV)','pH', 'Turbidity (NTU)', 'ODOSat%','ODO (mg/L)', 'Bloom']\n",
    "scaler = MinMaxScaler()\n",
    "ds_scaled = scaler.fit_transform(df_train[dataset_columns])\n",
    "df_train = pd.DataFrame(ds_scaled,columns=dataset_columns)\n",
    "\n",
    "ds_scaled = scaler.fit_transform(df_test[dataset_columns])\n",
    "df_test = pd.DataFrame(ds_scaled,columns=dataset_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to take a moving window of the data of 10 time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "determines the window size for the daata set\n",
    "@param dataset - The dataset to get windows for\n",
    "@param window_size - the size of the window  \n",
    "@param shift - the amout to shift the window\n",
    "'''\n",
    "def windows(dataset, window_size, shift):\n",
    "    start = 0\n",
    "    while start+window_size < dataset.shape[0]: \n",
    "        yield (int(start), int(start+window_size))\n",
    "        # shift the window five blocks of time\n",
    "        start += shift\n",
    "        if start % 300 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format(((start+window_size) / dataset.shape[0]) * 100 ))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Segments the dataset based on the parameters that are passed in.\n",
    "@param dataset - the dataset to segment into window\n",
    "@param columns - the array of columns from the dataset to be looked at\n",
    "@param window_size - the size of the window you would like to be looked at. Defualt is 10\n",
    "\n",
    "'''\n",
    "def segment_dataset(dataset, columns, target, window_size=10):    \n",
    "    print('WINDOW SIZE',window_size)\n",
    "    print('NUMBER OF COULUMNS',len(columns))\n",
    "    segments = np.empty((0, window_size, len(columns)))\n",
    "    labels = np.empty((0))\n",
    "    count = 0\n",
    "    for (start, end) in windows(dataset, window_size, 1):\n",
    "        count+=1\n",
    "        values = dataset[columns][start:end]\n",
    "        if(values.shape[0] == window_size):\n",
    "            segments = np.vstack([segments, np.stack([values])])\n",
    "            # Takes the larger of the two variables if there are more than one. \n",
    "            # This makes it more likly to predict a bloom. Can be changed to iloc[0] to\n",
    "            # be less likly to predict a bloom (more 0s in the label array)\n",
    "            \n",
    "            labels = np.append(labels, dataset[target][start:end].mode().iloc[-1])\n",
    "        else:\n",
    "            print(\"No more Windows available... Exiting\")\n",
    "            break\n",
    "    return (segments, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.63% done\n",
      "Window Segmentation 3.21% done\n",
      "Window Segmentation 4.80% done\n",
      "Window Segmentation 6.38% done\n",
      "Window Segmentation 7.96% done\n",
      "Window Segmentation 9.55% done\n",
      "Window Segmentation 11.13% done\n",
      "Window Segmentation 12.71% done\n",
      "Window Segmentation 14.30% done\n",
      "Window Segmentation 15.88% done\n",
      "Window Segmentation 17.46% done\n",
      "Window Segmentation 19.05% done\n",
      "Window Segmentation 20.63% done\n",
      "Window Segmentation 22.21% done\n",
      "Window Segmentation 23.80% done\n",
      "Window Segmentation 25.38% done\n",
      "Window Segmentation 26.96% done\n",
      "Window Segmentation 28.55% done\n",
      "Window Segmentation 30.13% done\n",
      "Window Segmentation 31.71% done\n",
      "Window Segmentation 33.30% done\n",
      "Window Segmentation 34.88% done\n",
      "Window Segmentation 36.46% done\n",
      "Window Segmentation 38.05% done\n",
      "Window Segmentation 39.63% done\n",
      "Window Segmentation 41.21% done\n",
      "Window Segmentation 42.80% done\n",
      "Window Segmentation 44.38% done\n",
      "Window Segmentation 45.97% done\n",
      "Window Segmentation 47.55% done\n",
      "Window Segmentation 49.13% done\n",
      "Window Segmentation 50.72% done\n",
      "Window Segmentation 52.30% done\n",
      "Window Segmentation 53.88% done\n",
      "Window Segmentation 55.47% done\n",
      "Window Segmentation 57.05% done\n",
      "Window Segmentation 58.63% done\n",
      "Window Segmentation 60.22% done\n",
      "Window Segmentation 61.80% done\n",
      "Window Segmentation 63.38% done\n",
      "Window Segmentation 64.97% done\n",
      "Window Segmentation 66.55% done\n",
      "Window Segmentation 68.13% done\n",
      "Window Segmentation 69.72% done\n",
      "Window Segmentation 71.30% done\n",
      "Window Segmentation 72.88% done\n",
      "Window Segmentation 74.47% done\n",
      "Window Segmentation 76.05% done\n",
      "Window Segmentation 77.63% done\n",
      "Window Segmentation 79.22% done\n",
      "Window Segmentation 80.80% done\n",
      "Window Segmentation 82.38% done\n",
      "Window Segmentation 83.97% done\n",
      "Window Segmentation 85.55% done\n",
      "Window Segmentation 87.13% done\n",
      "Window Segmentation 88.72% done\n",
      "Window Segmentation 90.30% done\n",
      "Window Segmentation 91.88% done\n",
      "Window Segmentation 93.47% done\n",
      "Window Segmentation 95.05% done\n",
      "Window Segmentation 96.63% done\n",
      "Window Segmentation 98.22% done\n",
      "Window Segmentation 99.80% done\n",
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.81% done\n",
      "Window Segmentation 3.56% done\n",
      "Window Segmentation 5.32% done\n",
      "Window Segmentation 7.07% done\n",
      "Window Segmentation 8.83% done\n",
      "Window Segmentation 10.58% done\n",
      "Window Segmentation 12.34% done\n",
      "Window Segmentation 14.09% done\n",
      "Window Segmentation 15.85% done\n",
      "Window Segmentation 17.60% done\n",
      "Window Segmentation 19.36% done\n",
      "Window Segmentation 21.11% done\n",
      "Window Segmentation 22.87% done\n",
      "Window Segmentation 24.62% done\n",
      "Window Segmentation 26.38% done\n",
      "Window Segmentation 28.13% done\n",
      "Window Segmentation 29.89% done\n",
      "Window Segmentation 31.64% done\n",
      "Window Segmentation 33.40% done\n",
      "Window Segmentation 35.15% done\n",
      "Window Segmentation 36.91% done\n",
      "Window Segmentation 38.66% done\n",
      "Window Segmentation 40.42% done\n",
      "Window Segmentation 42.17% done\n",
      "Window Segmentation 43.93% done\n",
      "Window Segmentation 45.68% done\n",
      "Window Segmentation 47.43% done\n",
      "Window Segmentation 49.19% done\n",
      "Window Segmentation 50.94% done\n",
      "Window Segmentation 52.70% done\n",
      "Window Segmentation 54.45% done\n",
      "Window Segmentation 56.21% done\n",
      "Window Segmentation 57.96% done\n",
      "Window Segmentation 59.72% done\n",
      "Window Segmentation 61.47% done\n",
      "Window Segmentation 63.23% done\n",
      "Window Segmentation 64.98% done\n",
      "Window Segmentation 66.74% done\n",
      "Window Segmentation 68.49% done\n",
      "Window Segmentation 70.25% done\n",
      "Window Segmentation 72.00% done\n",
      "Window Segmentation 73.76% done\n",
      "Window Segmentation 75.51% done\n",
      "Window Segmentation 77.27% done\n",
      "Window Segmentation 79.02% done\n",
      "Window Segmentation 80.78% done\n",
      "Window Segmentation 82.53% done\n",
      "Window Segmentation 84.29% done\n",
      "Window Segmentation 86.04% done\n",
      "Window Segmentation 87.80% done\n",
      "Window Segmentation 89.55% done\n",
      "Window Segmentation 91.31% done\n",
      "Window Segmentation 93.06% done\n",
      "Window Segmentation 94.82% done\n",
      "Window Segmentation 96.57% done\n",
      "Window Segmentation 98.33% done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "feature_columns = dataset_columns[:-1]\n",
    "(x_train, y_train) = segment_dataset(df_train, feature_columns, 'Bloom', 9)\n",
    "(x_test, y_test) = segment_dataset(df_test, feature_columns, 'Bloom', 9)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18938, 9, 7)\n",
      "(17086, 9, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18938,)\n",
      "(17086,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaping the data to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),9,7,1)\n",
    "x_test = x_test.reshape(len(x_test),9,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking apart training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (18938, 9, 7, 1)\n",
      "x_test shape: (17086, 9, 7, 1)\n",
      "y_train shape: (18938, 1)\n",
      "y_test shape: (17086, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"x_test shape:\",x_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mod = ks.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_mod = ks.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "input_shape = (9,7,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Activation, MaxPooling2D\n",
    "\n",
    "# Gets the precision of the different metrics\n",
    "def create_class_predictions(pred):\n",
    "    retval = np.array([])\n",
    "    for row in pred:\n",
    "        max_value = (-1,-1)\n",
    "        for index, value in enumerate(row):\n",
    "            if value > max_value[1]:\n",
    "                max_value = (index, value)\n",
    "        retval = np.append(retval, max_value[0])\n",
    "    return retval\n",
    "\n",
    "\n",
    "def create_layers(num_layers):\n",
    "    layers = [Flatten(), Dropout(0.2), Dense(NUM_CLASSES, activation='softmax', input_dim=2)]\n",
    "    for i in range(0, num_layers):\n",
    "        layers.insert(0, Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (18938, 9, 7, 1)\n",
      "x_train new shape: (18938, 9, 7, 1, 1)\n",
      "x_test shape: (17086, 9, 7, 1)\n",
      "x_test new shape: (17086, 9, 7, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "shape = x_train.shape\n",
    "print(\"x_train shape:\", shape)\n",
    "x_train = x_train.reshape(shape[0], shape[1], shape[2], shape[3], 1)\n",
    "print(\"x_train new shape:\", x_train.shape)\n",
    "\n",
    "shape = x_test.shape\n",
    "print(\"x_test shape:\", shape)\n",
    "x_test = x_test.reshape(shape[0], shape[1], shape[2], shape[3], 1)\n",
    "print(\"x_test new shape:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 7, 1, 44)          388256    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 7, 1, 44)       0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 7, 1, 44)          247984    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1, 7, 1, 44)       0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, 7, 1, 44)          247984    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 1, 7, 1, 44)       0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, 7, 1, 44)          759088    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 308)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 308)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 44)                13596     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 90        \n",
      "=================================================================\n",
      "Total params: 1,656,998\n",
      "Trainable params: 1,656,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      " 1600/18938 [=>............................] - ETA: 1:45 - loss: 0.6564 - acc: 0.9844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-1654d44b8cb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         metrics=['accuracy'])\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = (9, 7, 1, 1)\n",
    "conv_output_shape = (1, 7, 1, 44)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(ConvLSTM2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "model.add(Reshape(conv_output_shape))\n",
    "model.add(ConvLSTM2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Reshape(conv_output_shape))\n",
    "model.add(ConvLSTM2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Reshape(conv_output_shape))\n",
    "model.add(ConvLSTM2D(44, 7, activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(44))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "        optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "        metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL: 0.0\n",
      "PECISION: 0.0\n",
      "[[1888    0]\n",
      " [   6    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmcuw\\AppData\\Local\\Continuum\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "y = y_test.reshape(-1,)\n",
    "recall = recall_score(y, predict)\n",
    "precision = precision_score(y, predict)\n",
    "print(\"RECALL:\",recall)\n",
    "print(\"PECISION:\", precision)\n",
    "print(confusion_matrix(y, predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (17044, 9, 7, 1, 1)\n",
      "x_train new shape: (17044, 9, 7)\n",
      "x_test shape: (1894, 9, 7, 1, 1)\n",
      "x_test new shape: (1894, 9, 7)\n"
     ]
    }
   ],
   "source": [
    "shape = x_train.shape\n",
    "print(\"x_train shape:\", shape)\n",
    "x_train = x_train.reshape(shape[0], shape[1], shape[2])\n",
    "print(\"x_train new shape:\", x_train.shape)\n",
    "\n",
    "shape = x_test.shape\n",
    "print(\"x_test shape:\", shape)\n",
    "x_test = x_test.reshape(shape[0], shape[1], shape[2])\n",
    "print(\"x_test new shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 2)                 80        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "17044/17044 [==============================] - 15s 881us/step - loss: 0.3720 - acc: 0.9064\n",
      "Epoch 2/100\n",
      "17044/17044 [==============================] - 14s 828us/step - loss: 0.2714 - acc: 0.9224\n",
      "Epoch 3/100\n",
      "17044/17044 [==============================] - 15s 862us/step - loss: 0.2361 - acc: 0.9203\n",
      "Epoch 4/100\n",
      "17044/17044 [==============================] - 15s 880us/step - loss: 0.1964 - acc: 0.9223\n",
      "Epoch 5/100\n",
      "17044/17044 [==============================] - 15s 876us/step - loss: 0.1989 - acc: 0.9189\n",
      "Epoch 6/100\n",
      "17044/17044 [==============================] - 15s 885us/step - loss: 0.1656 - acc: 0.9156\n",
      "Epoch 7/100\n",
      "17044/17044 [==============================] - 16s 924us/step - loss: 0.1533 - acc: 0.9133\n",
      "Epoch 8/100\n",
      "17044/17044 [==============================] - 16s 959us/step - loss: 0.1262 - acc: 0.9057\n",
      "Epoch 9/100\n",
      "17044/17044 [==============================] - 16s 950us/step - loss: 0.1194 - acc: 0.9040\n",
      "Epoch 10/100\n",
      "17044/17044 [==============================] - 16s 946us/step - loss: 0.1125 - acc: 0.9044\n",
      "Epoch 11/100\n",
      "17044/17044 [==============================] - 16s 940us/step - loss: 0.1019 - acc: 0.9000\n",
      "Epoch 12/100\n",
      "17044/17044 [==============================] - 16s 942us/step - loss: 0.0869 - acc: 0.8965\n",
      "Epoch 13/100\n",
      "17044/17044 [==============================] - 17s 986us/step - loss: 0.0863 - acc: 0.8925\n",
      "Epoch 14/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0774 - acc: 0.8926\n",
      "Epoch 15/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0695 - acc: 0.8960\n",
      "Epoch 16/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0676 - acc: 0.8952\n",
      "Epoch 17/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0721 - acc: 0.8942\n",
      "Epoch 18/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0634 - acc: 0.8919\n",
      "Epoch 19/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0659 - acc: 0.8938\n",
      "Epoch 20/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0629 - acc: 0.8871\n",
      "Epoch 21/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0604 - acc: 0.8879\n",
      "Epoch 22/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0614 - acc: 0.8904\n",
      "Epoch 23/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0642 - acc: 0.8871\n",
      "Epoch 24/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0668 - acc: 0.8881\n",
      "Epoch 25/100\n",
      "17044/17044 [==============================] - 17s 997us/step - loss: 0.0634 - acc: 0.8902\n",
      "Epoch 26/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0615 - acc: 0.8919\n",
      "Epoch 27/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0630 - acc: 0.8861\n",
      "Epoch 28/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0593 - acc: 0.8835\n",
      "Epoch 29/100\n",
      "17044/17044 [==============================] - 21s 1ms/step - loss: 0.0599 - acc: 0.8809\n",
      "Epoch 30/100\n",
      "17044/17044 [==============================] - 20s 1ms/step - loss: 0.0571 - acc: 0.8787\n",
      "Epoch 31/100\n",
      "17044/17044 [==============================] - 20s 1ms/step - loss: 0.0649 - acc: 0.8783\n",
      "Epoch 32/100\n",
      "17044/17044 [==============================] - 21s 1ms/step - loss: 0.0626 - acc: 0.8807\n",
      "Epoch 33/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0598 - acc: 0.8734\n",
      "Epoch 34/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0609 - acc: 0.8776\n",
      "Epoch 35/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0659 - acc: 0.8717\n",
      "Epoch 36/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0586 - acc: 0.8801\n",
      "Epoch 37/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0591 - acc: 0.8781\n",
      "Epoch 38/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0599 - acc: 0.8785\n",
      "Epoch 39/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0593 - acc: 0.8874\n",
      "Epoch 40/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0579 - acc: 0.8867\n",
      "Epoch 41/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0583 - acc: 0.8835\n",
      "Epoch 42/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0574 - acc: 0.8893\n",
      "Epoch 43/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0585 - acc: 0.8810\n",
      "Epoch 44/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0592 - acc: 0.8875\n",
      "Epoch 45/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0543 - acc: 0.8833\n",
      "Epoch 46/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0562 - acc: 0.8868\n",
      "Epoch 47/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0606 - acc: 0.8907\n",
      "Epoch 48/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0525 - acc: 0.8969\n",
      "Epoch 49/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0580 - acc: 0.8935\n",
      "Epoch 50/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0552 - acc: 0.8929\n",
      "Epoch 51/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0577 - acc: 0.8984\n",
      "Epoch 52/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0573 - acc: 0.8969\n",
      "Epoch 53/100\n",
      "17044/17044 [==============================] - 20s 1ms/step - loss: 0.0538 - acc: 0.9061\n",
      "Epoch 54/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0547 - acc: 0.9020\n",
      "Epoch 55/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0532 - acc: 0.9068\n",
      "Epoch 56/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0560 - acc: 0.9047\n",
      "Epoch 57/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0554 - acc: 0.9041\n",
      "Epoch 58/100\n",
      "17044/17044 [==============================] - 20s 1ms/step - loss: 0.0567 - acc: 0.9025\n",
      "Epoch 59/100\n",
      "17044/17044 [==============================] - 20s 1ms/step - loss: 0.0531 - acc: 0.9016\n",
      "Epoch 60/100\n",
      "17044/17044 [==============================] - 20s 1ms/step - loss: 0.0527 - acc: 0.9024\n",
      "Epoch 61/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0555 - acc: 0.9031\n",
      "Epoch 62/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0505 - acc: 0.9044\n",
      "Epoch 63/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0540 - acc: 0.9020\n",
      "Epoch 64/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0547 - acc: 0.9069\n",
      "Epoch 65/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0513 - acc: 0.9077\n",
      "Epoch 66/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0494 - acc: 0.9091\n",
      "Epoch 67/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0506 - acc: 0.9127\n",
      "Epoch 68/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0505 - acc: 0.9122\n",
      "Epoch 69/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0451 - acc: 0.9118\n",
      "Epoch 70/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0515 - acc: 0.9128\n",
      "Epoch 71/100\n",
      "17044/17044 [==============================] - 17s 976us/step - loss: 0.0488 - acc: 0.9150\n",
      "Epoch 72/100\n",
      "17044/17044 [==============================] - 17s 982us/step - loss: 0.0463 - acc: 0.9194\n",
      "Epoch 73/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0449 - acc: 0.9200\n",
      "Epoch 74/100\n",
      "17044/17044 [==============================] - 17s 981us/step - loss: 0.0397 - acc: 0.9224\n",
      "Epoch 75/100\n",
      "17044/17044 [==============================] - 16s 945us/step - loss: 0.0424 - acc: 0.9222\n",
      "Epoch 76/100\n",
      "17044/17044 [==============================] - 16s 948us/step - loss: 0.0432 - acc: 0.9268\n",
      "Epoch 77/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0368 - acc: 0.9305\n",
      "Epoch 78/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0370 - acc: 0.9368\n",
      "Epoch 79/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0366 - acc: 0.9367\n",
      "Epoch 80/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0366 - acc: 0.9365\n",
      "Epoch 81/100\n",
      "17044/17044 [==============================] - 19s 1ms/step - loss: 0.0373 - acc: 0.9413\n",
      "Epoch 82/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0363 - acc: 0.9457\n",
      "Epoch 83/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0355 - acc: 0.9423\n",
      "Epoch 84/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0352 - acc: 0.9452\n",
      "Epoch 85/100\n",
      "17044/17044 [==============================] - 18s 1ms/step - loss: 0.0358 - acc: 0.9511\n",
      "Epoch 86/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0344 - acc: 0.9528\n",
      "Epoch 87/100\n",
      "17044/17044 [==============================] - 17s 972us/step - loss: 0.0314 - acc: 0.9562\n",
      "Epoch 88/100\n",
      "17044/17044 [==============================] - 16s 946us/step - loss: 0.0305 - acc: 0.9576\n",
      "Epoch 89/100\n",
      "17044/17044 [==============================] - 16s 936us/step - loss: 0.0321 - acc: 0.9630\n",
      "Epoch 90/100\n",
      "17044/17044 [==============================] - 16s 967us/step - loss: 0.0305 - acc: 0.9643\n",
      "Epoch 91/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: 0.0307 - acc: 0.9698\n",
      "Epoch 92/100\n",
      "17044/17044 [==============================] - 17s 976us/step - loss: 0.0338 - acc: 0.9705\n",
      "Epoch 93/100\n",
      "17044/17044 [==============================] - 16s 934us/step - loss: 0.0335 - acc: 0.9743\n",
      "Epoch 94/100\n",
      "17044/17044 [==============================] - 16s 933us/step - loss: 0.0325 - acc: 0.9742\n",
      "Epoch 95/100\n",
      "17044/17044 [==============================] - 17s 984us/step - loss: 0.0295 - acc: 0.9744\n",
      "Epoch 96/100\n",
      "17044/17044 [==============================] - 17s 984us/step - loss: 0.0292 - acc: 0.9742\n",
      "Epoch 97/100\n",
      "17044/17044 [==============================] - 17s 985us/step - loss: 0.0295 - acc: 0.9760\n",
      "Epoch 98/100\n",
      "17044/17044 [==============================] - 16s 957us/step - loss: 0.0343 - acc: 0.9752\n",
      "Epoch 99/100\n",
      "17044/17044 [==============================] - 16s 948us/step - loss: 0.0310 - acc: 0.9742\n",
      "Epoch 100/100\n",
      "17044/17044 [==============================] - 16s 929us/step - loss: 0.0262 - acc: 0.9745\n",
      "17044/17044 [==============================] - 5s 293us/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (9, 7)\n",
    "conv_output_shape = (1, 7, 1, 44)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(NUM_CLASSES, dropout=0.2, input_shape=input_shape))\n",
    "Dense(NUM_CLASSES, activation='softmax', input_dim=2)\n",
    "model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "        optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "        metrics=['accuracy'])\n",
    "model.build()\n",
    "print(model.summary())\n",
    "model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL: 0.0\n",
      "PECISION: 0.0\n",
      "[[1888    0]\n",
      " [   6    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmcuw\\AppData\\Local\\Continuum\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "y = y_test.reshape(-1,)\n",
    "recall = recall_score(y, predict)\n",
    "precision = precision_score(y, predict)\n",
    "print(\"RECALL:\",recall)\n",
    "print(\"PECISION:\", precision)\n",
    "print(confusion_matrix(y, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring dropout for deployment\n",
    "K.set_learning_phase(0)\n",
    " \n",
    "# Set a file path to save the model in.\n",
    "model_name = \"rnn_detection_model\"\n",
    "model_version = \"1\"\n",
    "tf_path = \"./../../saved_models/{}/{}\".format(model_name, model_version)\n",
    " \n",
    "# Get the session from the Keras back-end to save the model in TF format.\n",
    "with K.get_session() as sess:\n",
    "    tf.saved_model.simple_save(sess, tf_path, inputs={'input': model.input}, outputs={t.name: t for t in model.outputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
